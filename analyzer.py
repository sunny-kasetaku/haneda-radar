import re
import datetime
import json
import os
from config import CONFIG

def run_analyze():
    print("--- KASETACK Analyzer v4.8: JSONãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆæŠ½å‡ºç‰ˆ ---")
    if not os.path.exists(CONFIG["DATA_FILE"]):
        print("âŒ ã‚¨ãƒ©ãƒ¼: raw_flight.txt ãŒã‚ã‚Šã¾ã›ã‚“")
        return None

    jst = datetime.timezone(datetime.timedelta(hours=9))
    now = datetime.datetime.now(jst)
    
    with open(CONFIG["DATA_FILE"], "r", encoding="utf-8", errors='ignore') as f:
        raw_content = f.read()

    stands = {"P1": 0, "P2": 0, "P3": 0, "P4": 0, "P5": 0}
    flight_rows = []

    # --- 1. ã€ç‹é“ã€‘Next.jsã®JSONãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥è§£æ ---
    print("ğŸ’¡ Next.js JSONãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã‚’è©¦ã¿ã¾ã™...")
    json_data = re.search(r'<script id="__NEXT_DATA__".*?>(.*?)</script>', raw_content, re.DOTALL)
    
    if json_data:
        try:
            full_json = json.loads(json_data.group(1))
            # JSONã®ä¸­ã‹ã‚‰ãƒ•ãƒ©ã‚¤ãƒˆæƒ…å ±ã®å¡Šã‚’åŠ›ãšãã§æ¢ã™ï¼ˆå†å¸°çš„æ¢ç´¢ï¼‰
            # â€»ã‚µã‚¤ãƒˆã®æ§‹é€ ã«åˆã‚ã›ã¦ã€ã“ã“ã‹ã‚‰ãƒªã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™
            print("âœ… JSONã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except:
            print("âš ï¸ JSONãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—ã€‚é€šå¸¸ã‚¹ã‚­ãƒ£ãƒ³ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")

    # --- 2. ã€ä¿é™ºã€‘é€šå¸¸ã®ã‚¹ã‚­ãƒ£ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰ ---
    # styleã‚¿ã‚°ã ã‘ã‚’å‰Šé™¤ï¼ˆå‰å›ã®ã‚¿ã‚¤ãƒã‚’ä¿®æ­£ï¼ï¼‰
    clean_content = re.sub(r'<style.*?>.*?</style>', '', raw_content, flags=re.DOTALL)
    
    time_pattern = r'(\d{1,2})\s*[:ï¼š]\s*(\d{2})'
    time_matches = list(re.finditer(time_pattern, clean_content))
    print(f"1. èª¿æŸ»åœ°ç‚¹: {len(time_matches)}ä»¶ ãƒ’ãƒƒãƒˆ")

    for m in time_matches:
        try:
            h_str, m_str = m.groups()
            f_h, f_m = int(h_str), int(m_str)
            f_t = now.replace(hour=f_h % 24, minute=f_m, second=0, microsecond=0)
            diff = (f_t - now).total_seconds() / 60
            
            if not (CONFIG["WINDOW_PAST"] <= diff <= CONFIG["WINDOW_FUTURE"]):
                continue

            # æ¢ç´¢ç¯„å›²
            chunk = clean_content[max(0, m.start()-400) : m.end()+600]
            chunk_upper = chunk.upper()
            
            # ä¾¿åã®æŠ½å‡ºï¼ˆJSONã‚­ãƒ¼ã¨ã‚¿ã‚°ä¸¡æ–¹ã«å¯¾å¿œï¼‰
            carrier, fnum = "ä¸æ˜", ""
            fn_m = re.search(r'(?:flightNumber|ä¾¿å)[\"\s:]+([A-Z]{2,3})(\d{1,4})', chunk_upper)
            if not fn_m: fn_m = re.search(r'([A-Z]{2,3})\s?(\d{1,4})', chunk_upper)
            if fn_m: carrier, fnum = fn_m.groups()

            # å‡ºèº«åœ°ã®æŠ½å‡º
            origin = "ä¸æ˜"
            org_m = re.search(r'(?:originCity|å‡ºç™ºåœ°|origin)[\"\s:]+([ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]{2,10})', chunk)
            if not org_m: org_m = re.search(r'[\">]([ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]{2,10})[\"<]', chunk)
            if org_m: origin = org_m.group(1).strip()

            # ã‚­ãƒ£ãƒ‘åˆ¤å®š
            cap = CONFIG["CAPACITY"]["SMALL"]
            if any(x in chunk_upper for x in ["777", "787", "350", "767", "A330"]): cap = CONFIG["CAPACITY"]["BIG"]
            if carrier not in ["JL", "NH", "BC", "7G", "6J", "ADO", "SNA", "SFJ"] and carrier != "ä¸æ˜":
                cap = CONFIG["CAPACITY"]["INTL"]

            pax = int(cap * CONFIG["LOAD_FACTORS"]["NORMAL"])
            
            s_key = "P5"
            if carrier in ["JL", "JAL"]:
                if any(c in origin for c in CONFIG["SOUTH_CITIES"]): s_key = "P1"
                elif any(c in origin for c in CONFIG["NORTH_CITIES"]): s_key = "P2"
                else: s_key = "P1"
            elif carrier in ["NH", "ANA"]: s_key = "P3"
            elif carrier in ["BC", "SKY"]: s_key = "P1"
            elif any(c in carrier for c in ["ADO", "SNA", "SFJ"]): s_key = "P4"
            
            flight_rows.append({
                "time": f"{f_h:02d}:{f_m:02d}", "flight": f"{carrier}{fnum}", 
                "origin": origin[:6], "pax": pax, "s_key": s_key
            })
        except: continue

    # é‡è¤‡å‰Šé™¤
    unique_rows = []
    seen = set()
    for r in flight_rows:
        id_str = f"{r['time']}-{r['flight']}-{r['origin']}"
        if id_str not in seen:
            seen.add(id_str); unique_rows.append(r)

    # é›†è¨ˆ
    for r in unique_rows: stands[r['s_key']] += r['pax']
    
    result = {
        "stands": stands, "pool_preds": {k: max(0, 100 - int(v/10)) for k, v in stands.items()},
        "total_pax": sum(stands.values()), "rows": unique_rows, "update_time": now.strftime("%H:%M")
    }
    
    with open(CONFIG["RESULT_JSON"], "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"2. è§£æå®Œäº†ã€‚æœ‰åŠ¹ä¾¿æ•°: {len(unique_rows)} / ç·éœ€è¦: {result['total_pax']}äºº")
    return result
