import re, datetime, json, os, unicodedata
from config import CONFIG

def run_analyze():
    print("--- KASETACK Analyzer v16.1: ç¾å ´èªå½™ãƒ»å®Œå…¨ä¸€è‡´ç‰ˆ ---")
    if not os.path.exists(CONFIG["DATA_FILE"]): return None

    jst = datetime.timezone(datetime.timedelta(hours=9))
    now = datetime.datetime.now(jst)
    
    with open(CONFIG["DATA_FILE"], "r", encoding="utf-8", errors='ignore') as f:
        raw_html = f.read()

    # å‰å‡¦ç†ï¼šæ­£è¦åŒ–
    content = unicodedata.normalize('NFKC', raw_html)
    text = re.sub(r'<(style|script)[^>]*>.*?</\1>', ' ', content, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<[^>]+>', ' ', text)
    text = re.sub(r'\s+', ' ', text)

    # ğŸ” ã€è¨¼æ‹ é–‹ç¤ºã€‘å†’é ­ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
    print(f"\n--- ğŸ“‹ å–å¾—ãƒ‡ãƒ¼ã‚¿æ–­ç‰‡ (JAL/ANA/ã‚¨ã‚¢ãƒ‰ã‚¥ã‚’æ¢ã›ï¼) ---")
    print(text[text.find("åˆ°ç€"):text.find("åˆ°ç€")+1000]) # ã€Œåˆ°ç€ã€ã¨ã„ã†æ–‡å­—å‘¨è¾ºã‚’è¡¨ç¤º
    print(f"-----------------------------------\n")

    stands = {"P1": 0, "P2": 0, "P3": 0, "P4": 0, "P5": 0}
    active_rows = []
    found_all_list = []

    # ğŸŒŸ ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼ã®ç›®è¦–æƒ…å ±ã‚’è¾æ›¸ã«å®Œå…¨åæ˜ 
    carrier_map = {
        "ANA": ["å…¨æ—¥æœ¬ç©ºè¼¸", "ANA", "å…¨æ—¥ç©º"],
        "JAL": ["æ—¥æœ¬èˆªç©º", "JAL", "JL"],
        "ADO": ["ã‚¨ã‚¢ãƒ‰ã‚¥", "AIRDO", "AIR DO"],
        "SNA": ["ã‚½ãƒ©ã‚·ãƒ‰ ã‚¨ã‚¢", "ã‚½ãƒ©ã‚·ãƒ‰", "SNJ"],
        "SKY": ["ã‚¹ã‚«ã‚¤ãƒãƒ¼ã‚¯", "SKY", "BC"]
    }

    time_matches = list(re.finditer(r'(\d{1,2}:\d{2})', text))
    print(f"1. ãƒšãƒ¼ã‚¸å†…ã« {len(time_matches)} å€‹ã®æ™‚åˆ»ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèªã€‚ç²¾æŸ»é–‹å§‹...")

    for m in time_matches:
        time_str = m.group(1)
        chunk = text[m.start() : m.start() + 300].upper()
        
        found_c = None
        for code, keywords in carrier_map.items():
            if any(kw.upper() in chunk for kw in keywords):
                found_c = code; break
        
        if not found_c: continue
        
        origin = "ä¸æ˜"
        for city in (CONFIG["SOUTH_CITIES"] + CONFIG["NORTH_CITIES"]):
            if city in chunk:
                origin = city; break

        found_all_list.append(f"[{time_str} {found_c} ({origin})]")

        # éœ€è¦çª“åˆ¤å®š (T-30 ã€œ T+45)
        h, m_val = map(int, time_str.split(':'))
        f_t = now.replace(hour=h, minute=m_val, second=0, microsecond=0)
        diff = (f_t - now).total_seconds() / 60
        if diff < -720: f_t += datetime.timedelta(days=1); diff += 1440
        elif diff > 720: f_t -= datetime.timedelta(days=1); diff -= 1440

        if CONFIG["WINDOW_PAST"] <= diff <= CONFIG["WINDOW_FUTURE"]:
            active_rows.append({"time": time_str, "flight": found_c, "origin": origin, "pax": 150, "s_key": "P1"})

    print(f"--- ğŸ“Š æœ€çµ‚ç›£æŸ»å ±å‘Š ---")
    if found_all_list:
        print(f"âœ… ç™ºæ˜æˆåŠŸï¼ è¨ˆ {len(found_all_list)} ä»¶ã‚’ç¢ºèªã€‚")
        print(f"ã‚µãƒ³ãƒ—ãƒ«: {', '.join(found_all_list[:5])}")
    else:
        print(f"âŒ ä¾ç„¶ã¨ã—ã¦æœ‰åŠ¹ãªä¾¿ãŒè¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€‚")
    print(f"----------------------")

    result = {"stands": stands, "total_pax": len(active_rows)*150, "rows": active_rows, "total_flights_on_page": len(found_all_list), "update_time": now.strftime("%H:%M")}
    with open(CONFIG["RESULT_JSON"], "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    return result
